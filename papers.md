# Everything I know

Everything I (or any researcher) know came from papers, and if I ever learned anything in a classroom it did not last. While the literature review is an important part of the research process, starting to engage with a new body of scientific literature can be overwhelming. Therefore, I will be continually curating the following list of papers. While there are no specific criterias, I believe these papers are especially engaging / well-written / fundamental / wild. Being honest, anything clever I ever said is probably a remastered version of ideas you will find here. Read those and you should know everything I know.

If you are a member of the lab, email me and I will send a drive link for pdfs with my own marginalia (I like to think of those scribbles as a very slow conversation).

* ###  __Computational Cognitive Neuroscience__  
  * ####  __Neural Networks As Cognitive Models__
    * __*(Yamis & Dicarlo 2016) Using goal-driven deep learning models to understand sensory cortex*__ : Overview of the very first papers to use Neural  Networks as cognitive models
    * __*Unsupervised neural network models of the ventral visual stream*__ : Really well written and interesting
    * __*Brain-like functional specialization emerges spontaneously in deep neural networks*__ : As a graduate student Nancy Kanwisher discovered that brain regions such as the FFA are specialized to perform specific tasks, she collaborates with her previous-student (Kathrine Dobs) on work that uses ANN to answer questions regarding why and where this specialization emerges. Their labs are good ones to follow. 
    * __*Driving and suppressing the human language network using large language models*__ : Using LLM embeddings to predict brain activation
    * __*Joint processing of linguistic properties in brains and language models*__ : Using LLM embeddings to specifically detect what different brain regions encode 
  * ####  __Language Acquisition__
    * __*Self-supervised learning through the eyes of a child*__: Chomsky talked about the poverty of stimuli as a motivation for the necessity of innate language processes, computational results here complicate this debate.
    * __*Grounded language acquisition through the eyes and ears of a single child*__: Similar ideas, improved execution!
    * __*Helpless infants are learning a foundation model*__: Why are human babies useless? they are training a MMLLM!
  * ####  __Motor Functions and Embodied Intelligence__
    * __*Your head is there to move you around: Goal-driven models of the primate dorsal pathway*__: All the papers so far focused on the ventral (what / semantic) brain pathway, here we look at the dorsal (motor / movement / where) pathway
    * __*The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning*__: Your brain has two pathways (we think), should your network?
    * __*Multitask representations in the human cortex transform along a sensory-to-motor hierarchy*__: Follow Takuya Ito, his methods differ from the common regression / RSA, and that's a good thing.
    * __*Compositional generalization through abstract representations in human and artificial neural networks*__: Another Takuya Ito, worth it for the dataset.
  * ####  __Other Cognitive Neuroscience__
    * __*Reconstructing visual illusory experiences from human brain activity*__: Reconstructing what we are looking at from brain activity was not enough for Kamitani, instead he also reconstructs subjective experience such as illusions  
* ###  __(Multi-Modal) Large Language Models__
  * ####  __The Classics__
    * __*LLaMA: Open and Efficient Foundation Language Models*__ : The one and only original open LLM
    * __*SELF-INSTRUCT: Aligning Language Model with Self Generated Instructions*__ : The jump from GPT-3 to ChatGPT. How to train networks to follow isntructions and complete tasks. I argue it's mostly just stylistic alligment
    * __*Evaluating Moral Beliefs Encoded in LLMs*__ : Another prompt, another PR nightmare... LLMs are laying waste to the creative industries, but will Roko's basilisk be woke?
* ###  __Philosophy__  
  * ####  __Are Neural Networks Cognitive Models?__
    * __*The Neuroconnectionist Research Programme*__ : What can computational models actually tell us? very important discussion, but I disagree with most of this paper.
  * ####  __Other__
    * __*Memory as a cognitive kind: Brains, remembering dyads, and exograms*__ : What is a kind / Class / Group? Are cognitive mechanisims such as attention and memory just a story cognitive psychologist tell themselves? 
